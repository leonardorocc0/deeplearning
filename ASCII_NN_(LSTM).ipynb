{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ASCII NN (LSTM).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfSoMn/xfmVavTUo6Q8bDF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardorocc0/deeplearning/blob/main/ASCII_NN_(LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvBn7QkR1B5b"
      },
      "source": [
        "\"\"\"\n",
        "\n",
        "ver este video:\n",
        "    https://www.youtube.com/watch?v=VAMKuRAh2nc\n",
        "NLP Tutorial 11 - Automatic Text Generation using TensorFlow, Keras and LSTM\n",
        "\n",
        "https://github.com/shywel/NLP-Tutorial-11---Automatic-Text-Generation-using-TensorFlow-Keras-and-LSTM/blob/master/Automatic_Text_Generation_Using_Keras_and_LSTM.ipynb\n",
        "\n",
        "@author: Leo\n",
        "\"\"\"\n",
        "https://towardsdatascience.com/generating-eminem-lyrics-using-neural-networks-96e7f9c45e8a\n",
        "\n",
        "https://machinelearningmastery.com/how-to-load-convert-and-save-images-with-the-keras-api/\n",
        "\n",
        "----------------------------------------------------------------------------------------\n",
        "# generador de texto usando keras ----------------------------------------------------------------------------------------\n",
        "# siguiendo este ejemplo:\n",
        "https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
        "https://rodarmor.com/artnet/\n",
        "https://github.com/karpathy/char-rnn\n",
        "\n",
        "https://github.com/TannerGilbert/Tutorials/blob/master/Keras-Tutorials/4.%20LSTM%20Text%20Generation/Keras%20LSTM%20Text%20Generation.ipynb\n",
        " ver de sacar cosas de art ascii generator: https://github.com/casey/artnet/blob/master/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUjNMyJG1ybG"
      },
      "source": [
        "\n",
        "siguiendo generador de texto de eminem lo podria adaptar: \n",
        "https://towardsdatascience.com/generating-eminem-lyrics-using-neural-networks-96e7f9c45e8a    \n",
        "https://github.com/rojagtap/eminem_lyrics_generator/blob/master/generator.ipynb\n",
        "o este mejor:\n",
        "https://github.com/TannerGilbert/Tutorials/blob/master/Keras-Tutorials/4.%20LSTM%20Text%20Generation/Keras%20LSTM%20Text%20Generation.ipynb\n",
        "q es de este video https://www.youtube.com/watch?v=QtQt1CUEE3w"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FHoMkJCwNJu"
      },
      "source": [
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEsP9ZeH0FpE"
      },
      "source": [
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "import keras.models\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import requests\n",
        "import io"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TRglo7tz5EW"
      },
      "source": [
        "#response = requests.get('http://cloud.pungas.space/index.php/s/md8f6ABpMPM5nbf/download') #si bajamos de pungas cloud ponerle el /download"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c70TDROMG5Lz"
      },
      "source": [
        "#anda bien lo de abajo pero se cayo nextcloud :(\n",
        "#files_asciis = ['https://cloud.pungas.space/index.php/s/qW2kcBAxcio23e2/download','http://cloud.pungas.space/index.php/s/md8f6ABpMPM5nbf/download','https://cloud.pungas.space/index.php/s/p7Q4gbEppDdz9Nt/download','https://cloud.pungas.space/index.php/s/iQ5qrbTWzCZDZx7/download','https://cloud.pungas.space/index.php/s/5xHDRCNGLikmZHE/download','https://cloud.pungas.space/index.php/s/WDcJJgARayQFfen/download','https://cloud.pungas.space/index.php/s/iyLNFrB6KtmtxR7/download','https://cloud.pungas.space/index.php/s/7DaSRokk4TZp6CK/download','https://cloud.pungas.space/index.php/s/ZpL6aT2c9jL4Twb/download','https://cloud.pungas.space/index.php/s/Xt5igHetkZBKWmG/download']\n",
        "#files_asciis = ['https://16colo.rs/pack/mimic78/raw/ds%21-ill.txt','https://16colo.rs/pack/ds-fire/raw/ds%21-fire.txt','https://16colo.rs/pack/se-zeit/raw/se-zeit.txt']\n",
        "files_asciis = ['https://16colo.rs/pack/mimic78/raw/ds%21-ill.txt','https://16colo.rs/pack/ds-fire/raw/ds%21-fire.txt','https://16colo.rs/pack/se-zeit/raw/se-zeit.txt','http://cloud.pungas.space/s/ZfzanT3R8xkHASz/download','https://cloud.pungas.space/s/Wzc9N7EBSTgPFtD/download','https://cloud.pungas.space/s/xQ9bmL8zC5dZBnB/download','https://cloud.pungas.space/s/xQ9bmL8zC5dZBnB/download','https://cloud.pungas.space/s/F82Dc9mJRDgeQCB/download','https://cloud.pungas.space/s/cbtg5SicMweQGYe/download','https://cloud.pungas.space/s/4LWQXwcmXY95HMx/download','https://cloud.pungas.space/s/xaxKY62XxkKGRRt/download','https://cloud.pungas.space/s/AXYHccTpBB7tofS/download','https://cloud.pungas.space/s/kd6qk36QFEn4wqg/download','https://cloud.pungas.space/s/7biscC4oRTDQbF5/download','https://cloud.pungas.space/s/RLQYkybqWeP8NL3/download','https://cloud.pungas.space/s/WwxEDmwqWpxqMSB/download','https://cloud.pungas.space/s/o7aQcZJBNcot5q7/download','https://cloud.pungas.space/s/oo2ajY8d9bk7t2j/download','https://cloud.pungas.space/s/9LydGbzJga6PqSL/download','https://cloud.pungas.space/s/QkLNFSrjkMex2G3/download']\n",
        "#,'https://subcultura.digital/arleka/a!-ssr.txt','https://subcultura.digital/arleka/a!-fuckd.txt','https://subcultura.digital/arleka/asl-ads.txt','https://subcultura.digital/arleka/se-late.txt','https://subcultura.digital/arleka/se-getse.txt','https://subcultura.digital/arleka/lp-fs.txt','https://subcultura.digital/arleka/ed-mjau.txt','https://subcultura.digital/arleka/dz-fow.txt','https://subcultura.digital/arleka/ds-home.txt','https://subcultura.digital/arleka/ds!-ttya.txt','https://subcultura.digital/arleka/ds!-dive.txt','https://subcultura.digital/arleka/azk-fame.txt','https://subcultura.digital/arleka/asl-ftm.txt']"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8huEDcXJ09H"
      },
      "source": [
        "# agregamos todas las collies de files_asciis\n",
        "lines = '' \n",
        "for filename in files_asciis: \n",
        "  file = requests.get(filename)\n",
        "  lines += file.text"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4Lv-jaA1ZFI"
      },
      "source": [
        "# load ascii text y mostrarlo que ande bien\n",
        "#raw_text = response.text\n",
        "raw_text = lines"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx8o9AZg1taF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db052da7-58ac-4b8c-c3b9-51e32d938952"
      },
      "source": [
        "# QA\n",
        "# si queremos ver que cargo bien...\n",
        "print(raw_text[-10000:])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_ .                      / __///\r\n",
            "     / /       ____ . _____ .  \\\\   \\ __ /   //  . _____ . ____       \\ \\\r\n",
            " _  / /___  __ \\  /  \\\\ _ //  � \\\\__ /  \\ __// �  \\\\ _ //  \\  / __  ___\\ \\  _\r\n",
            " \\\\\\\\____(�(_//~\\/(((__(_)__))--//   \\__/   \\\\--((__(_)__)))\\/~\\\\_)�)____////\r\n",
            "              ~~~    //___\\\\  ///___/    \\___\\\\\\  //___\\\\    ~~~\r\n",
            "                                    \\____/\r\n",
            "\r\n",
            "\r\n",
            "     ___ _\r\n",
            "    / _///_________//\\____ _         _ ______ _\r\n",
            "_ __\\______   \\__        ///__/\\_____\\\\\\    ///_____ _\r\n",
            "/  //     /     \\)______/         \\    /           ///___  _ ____  _  mkd1981\r\n",
            "    \\_   /             \\__   \\____/   /           /     /__\\\\\\_ /_//\\_____\r\n",
            "      \\___               //  /     _  \\          /       __        __     \\\\\r\n",
            "         //____             /     / \\__         /        \\(         \\_____/\r\n",
            ".-------------//________         /---//_______      _____ \\       __/     \\__\r\n",
            "|   s E c u l A r      //_______\\\\         ///__  __\\\\   \\__    __\\___      /_\r\n",
            "`-----------------------------------------------\\/--------//____\\\\   \\\\______///\r\n",
            "\r\n",
            "                                    .___.\r\n",
            "    _______________/\\________________) (_________________/\\_______________\r\n",
            "    \\_                                                                  _/\r\n",
            "     |                                                                  |\r\n",
            " _ __|_  :sYNTHETIK wORLD:           ____                              _|__ _\r\n",
            " \\\\\\__ \\                      . ____/    \\____ .                      / __///\r\n",
            "     / /       ____ . _____ .  \\\\   \\ __ /   //  . _____ . ____       \\ \\\r\n",
            " _  / /___  __ \\  /  \\\\ _ //  � \\\\__ /  \\ __// �  \\\\ _ //  \\  / __  ___\\ \\  _\r\n",
            " \\\\\\\\____(�(_//~\\/(((__(_)__))--//   \\__/   \\\\--((__(_)__)))\\/~\\\\_)�)____////\r\n",
            "              ~~~    //___\\\\  ///___/    \\___\\\\\\  //___\\\\    ~~~\r\n",
            "                                    \\____/\r\n",
            "\r\n",
            "   ___    _______   ____________________ _________________ _____      _____\r\n",
            " // _//__\\\\     /__\\\\_   \\_     __  ___/_\\__     /_     _/_\\___//___//    //\r\n",
            " _\\____    \\   /     /    /     \\/  \\      \\____/_/     \\/                \\\r\n",
            "\\\\__  /   __      __/    /__      __/    ___      __      __      __/      \\\\\r\n",
            "  #/_____/#/_____/#/____/##/_____/#/____/##/_____/#/_____/#/_____/#/________\\\r\n",
            "      ________      ____________________________________         _______\r\n",
            "     \\\\      /\\_____\\          _                       //_______\\\\      \\__\r\n",
            " mkd   \\                       /           /__ /      /         _         //\r\n",
            "      //_____/\\     /___          ___     /   /___          ___ \\        / r81\r\n",
            " :::##########\\\\___/###\\\\________/##\\\\___//######\\\\________/###\\________/##:::\r\n",
            "[80x50]\r\n",
            "\r\n",
            "\r\n",
            "                                    .___.\r\n",
            "    _______________/\\________________) (_________________/\\_______________\r\n",
            "    \\_                                                                  _/\r\n",
            "     |                                                                  |\r\n",
            " _ __|_  :zOOVY:                     ____                              _|__ _\r\n",
            " \\\\\\__ \\                      . ____/    \\____ .                      / __///\r\n",
            "     / /       ____ . _____ .  \\\\   \\ __ /   //  . _____ . ____       \\ \\\r\n",
            " _  / /___  __ \\  /  \\\\ _ //  � \\\\__ /  \\ __// �  \\\\ _ //  \\  / __  ___\\ \\  _\r\n",
            " \\\\\\\\____(�(_//~\\/(((__(_)__))--//   \\__/   \\\\--((__(_)__)))\\/~\\\\_)�)____////\r\n",
            "              ~~~    //___\\\\  ///___/    \\___\\\\\\  //___\\\\    ~~~\r\n",
            "                                    \\____/\r\n",
            "\r\n",
            "     _______   _____/\\\\______________________      ____/\\\\___       _______\r\n",
            "   _\\\\____  \\  \\       _      \\       _     //____\\\\        //____//      //\r\n",
            " _/     ____//_/       /      /       /     //     /       /     _/     _/mkd\r\n",
            " \\      \\      /             /               \\    /       /\\_    \\      \\_\r\n",
            " \\\\___  \\\\    /___          /_____           _\\          // /_           //\r\n",
            " :###/_   ___/###/_________/#####/____  ____/##\\_________\\####\\___  ____/###:\r\n",
            "       \\//                           \\\\/                          \\//\r\n",
            "               [ zOOVy ]\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "    _____    _____________________    ._______  ._______\r\n",
            "  _\\\\__  \\_//      _    /     _  //___|      /__|      //\r\n",
            "--\\   ___/  \\      /   //     /  \\    |    //   |   __/----------------------\r\n",
            "  \\\\  \\     _\\        /__        /__  |    /__      \\_       z  o  o  v  y\r\n",
            "[==/_______/=/_______/==/_______/==/_______\\=/_______//===]\r\n",
            "---mkdR81-------------------------------------------------------------------\r\n",
            "\r\n",
            "-\r\n",
            "                                    .___.\r\n",
            "    _______________/\\________________) (_________________/\\_______________\r\n",
            "    \\_                                                                  _/\r\n",
            "     |                                                                  |\r\n",
            " _ __|_  :dEAd fLORa:                ____                              _|__\r\n",
            " \\ \\__ \\                      . ____/    \\____ .                      / __///\r\n",
            "     / /       ____ . _____ .  \\\\   \\ __ /   //  . _____ . ____       \\ \\\r\n",
            " _  / /___  __ \\  /  \\\\ _ //  � \\\\__ /  \\ __// �  \\\\ _ //  \\  / __  ___\\ \\  _\r\n",
            " \\\\\\\\____(�(_//~\\/(((__(_)__))--//   \\__/   \\\\--((__(_)__)))\\/~\\\\_)�)____////\r\n",
            "              ~~~    //___\\\\  ///___/    \\___\\\\\\  //___\\\\    ~~~\r\n",
            "                                    \\____/\r\n",
            "\r\n",
            "                                                                               \r\n",
            "                                                                               \r\n",
            "                              ::::::::::::::                                   \r\n",
            "                           ::::::::::::                                        \r\n",
            "                       ::::::::::::::::::::                                    \r\n",
            "                            ::::::::::::::::::          mkd+slO\r\n",
            "          ____________.________    ___________.____________ ___________        \r\n",
            "         _|      _____/       /___|           |           /_\\______  _//_ __   \r\n",
            "    _ __\\\\__         ||      /    |      _    |    _   - /    _   /  |         \r\n",
            "          |__       _|/__         |__         |_____\\     \\__ \\      |         \r\n",
            "          ::/______|::::/_________|:/_________|::::::\\____\\:/________/         \r\n",
            "                          ::::::::::::::::::::                                 \r\n",
            "           d  E         ::::A:D:::::::::f:L:    O     R       A                \r\n",
            "                      ::::::::::::::::::::::::                                 \r\n",
            "                             :::::::::::                                       \r\n",
            "                               ::::                                            \r\n",
            "                                :                                              \r\n",
            "                                :                      \r\n",
            "\r\n",
            "\r\n",
            "                                    .___.\r\n",
            "    _______________/\\________________) (_________________/\\_______________\r\n",
            "    \\_                                                                  _/\r\n",
            "     |                                                                  |\r\n",
            " _ __|_  :zERO hOUR:                 ____                              _|__ _\r\n",
            " \\\\\\__ \\                      . ____/    \\____ .                      / __///\r\n",
            "     / /       ____ . _____ .  \\\\   \\ __ /   //  . _____ . ____       \\ \\\r\n",
            " _  / /___  __ \\  /  \\\\ _ //  � \\\\__ /  \\ __// �  \\\\ _ //  \\  / __  ___\\ \\  _\r\n",
            " \\\\\\\\____(�(_//~\\/(((__(_)__))--//   \\__/   \\\\--((__(_)__)))\\/~\\\\_)�)____////\r\n",
            "              ~~~    //___\\\\  ///___/    \\___\\\\\\  //___\\\\    ~~~\r\n",
            "                                    \\____/\r\n",
            "\r\n",
            "\r\n",
            "                          ____     __//\\___     _______    __//\\__\r\n",
            "                         _\\  //  __\\      /_ __\\\\     /____\\     /__ _\r\n",
            "                    _ __\\\\__   \\\\\\_         \\            \\         ///\r\n",
            "                    \\\\\\   _____/_/ \\__      /            /      _  \\\r\n",
            "   .__________________/   \\      \\   \\_____//       \\           /   \\\r\n",
            "   |                _\\   //      /                  /____           /_\r\n",
            "   |.      .--------\\\\\\_                 _____    //____\\_         ///-----.\r\n",
            "   |:     _|    _ ______\\___             \\\\  _\\   /       \\        \\---.   |\r\n",
            "   ||    \\\\_    \\\\\\         \\\\/          /__\\\\                      \\  |  .|\r\n",
            "   ||      |  .---/         //         _      \\                     /  |  :|\r\n",
            "   ||      `--|  /    _____/_\\         /      /                 /  /_  |_ :|\r\n",
            "   |.  .------'_/    \\\\                     //         /       /___\\\\\\ _//||\r\n",
            "   |   |  .---\\\\______/       __          _ /        _/_      /%%%%%%: |  ||\r\n",
            "   |:  `--| :%%%%%%%%/_      /%%\\        /%\\_       /%%\\_    /% .------'  ||\r\n",
            "   |______`-------. %%/______\\%%%\\______/%%%/_______\\%%%/____\\% |         ||\r\n",
            "   |      \\_______| %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% | mkdRMRS ||\r\n",
            "   |              `---------------------------------------------'         :|\r\n",
            "   |_______________________________________________________________________|\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "                                    .___.\r\n",
            "    _______________/\\________________) (_________________/\\_______________\r\n",
            "    \\_                                                                  _/\r\n",
            "     |                                                                  |\r\n",
            " _ __|_  :zMEJ:                      ____                              _|__ _\r\n",
            " \\\\\\__ \\                      . ____/    \\____ .                      / __///\r\n",
            "     / /       ____ . _____ .  \\\\   \\ __ /   //  . _____ . ____       \\ \\\r\n",
            " _  / /___  __ \\  /  \\\\ _ //  � \\\\__ /  \\ __// �  \\\\ _ //  \\  / __  ___\\ \\  _\r\n",
            " \\\\\\\\____(�(_//~\\/(((__(_)__))--//   \\__/   \\\\--((__(_)__)))\\/~\\\\_)�)____////\r\n",
            "              ~~~    //___\\\\  ///___/    \\___\\\\\\  //___\\\\    ~~~\r\n",
            "                                    \\____/\r\n",
            "\r\n",
            "          _ ____\r\n",
            "       ___\\\\\\_  \\\\ _ ___/\\\\_________/\\\\_____  _ __/\\\\__\r\n",
            "      \\\\   _____/__\\\\\\_____   \\\\_          /  \\\\\\_     \\\\\r\n",
            "      _/   \\           /  /      \\________//_____/     /\r\n",
            "      \\    /          /  /                \\     /     //\r\n",
            ".=====\\\\_        ____/  /     __           _    \\    /========================.\r\n",
            "| ...::%%\\__  __/%%%/__/_  __/%%\\____  ___/%\\__  ____\\%::: z : m : e : j :... |\r\n",
            "`===========\\//==========\\//=========\\//=======\\//===============mkdR81======='\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "[eof]\r\n",
            "\r\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to9IQMzk1kEt"
      },
      "source": [
        "#remove unnecessary letters. WARNING: oldschool ascii art contains all kind of letters :)\n",
        "raw_text = raw_text.lower()\n",
        "#for char in 'abcdefghijklmnopqrstuvwxyz0123456789':\n",
        "for char in 'abcdefghijklmnopqrstuvwxyz0123456789¤µ¹âåäéëê¸±¶áßæ°ñ·¬ø¡½þúöó?#':\n",
        "    raw_text = raw_text.replace(char,' ')\n",
        "#    print(char)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAGFrORL15H0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5614f91c-767d-4196-843d-3ff6cca4f51e"
      },
      "source": [
        "#Map chars to integers\n",
        "# create mapping of unique chars to integers\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))  #char to int\n",
        "\"\"\"eg: '#': 4,\n",
        " '$': 5,\n",
        " '%': 6\"\"\"\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))   #int to char\n",
        "\"\"\"Eg: 4: '#',\n",
        " 5: '$',\n",
        " 6: '%',\"\"\""
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Eg: 4: '#',\\n 5: '$',\\n 6: '%',\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUrMW-v30Odw",
        "outputId": "6f0189e8-3aba-40af-d8ba-581ded17e46a"
      },
      "source": [
        "#QA check left over charset\n",
        "print(len(set(raw_text)))\n",
        "set(raw_text)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\x03',\n",
              " '\\t',\n",
              " '\\n',\n",
              " '\\x0c',\n",
              " '\\r',\n",
              " '\\x16',\n",
              " '\\x1b',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '@',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '^',\n",
              " '_',\n",
              " '`',\n",
              " '{',\n",
              " '|',\n",
              " '}',\n",
              " '~',\n",
              " '\\x7f',\n",
              " '¦',\n",
              " '©',\n",
              " '¯',\n",
              " '´',\n",
              " 'í',\n",
              " '÷',\n",
              " 'ţ',\n",
              " 'ư',\n",
              " 'ƴ',\n",
              " 'ƹ',\n",
              " 'ǵ',\n",
              " 'ɵ',\n",
              " 'ʃ',\n",
              " 'ʈ',\n",
              " 'ʋ',\n",
              " 'ά',\n",
              " 'ζ',\n",
              " 'ϯ',\n",
              " 'ϰ',\n",
              " 'ϵ',\n",
              " '϶',\n",
              " 'х',\n",
              " 'ѯ',\n",
              " 'ѵ',\n",
              " 'ַ',\n",
              " 'װ',\n",
              " 'ة',\n",
              " 'خ',\n",
              " 'د',\n",
              " 'ذ',\n",
              " 'ز',\n",
              " 'ش',\n",
              " 'ص',\n",
              " 'ض',\n",
              " 'ظ',\n",
              " 'ع',\n",
              " 'ڬ',\n",
              " 'ޤ',\n",
              " 'ް',\n",
              " '\\u07b5',\n",
              " '\\u07b6',\n",
              " 'ߣ',\n",
              " '\\u2d75',\n",
              " '浬',\n",
              " '浵',\n",
              " '涰',\n",
              " '�',\n",
              " '\\U000b5d75'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuHkaJqv3R0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b439fdd-62be-4649-d08c-838feb0a5d2b"
      },
      "source": [
        "#Split up into subsequences\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "# each character has a chance to be learned from the (seq_lenght) characters that preceded \n",
        "# it (except the first seq_lenght characters of course).\n",
        "\n",
        "maxlen = 80  #probar con 40 o mas, cuanto mas mejor\n",
        "step = 10\n",
        "sentences = []\n",
        "\"\"\"Eg sentences:\n",
        "     '   /__/  _   /\\\\_  _  /__/  /___/\\\\_ _/__/',\n",
        " '/__/  _   /\\\\_  _  /__/  /___/\\\\_ _/__/ __',\n",
        " \"\"\"\n",
        "next_chars = []\n",
        "\"\"\"Eg next_chars:\n",
        "    ' ',\n",
        " '_',\n",
        " '/',\"\"\"\n",
        "# basicamente lo que vamos a hacer es recorrer todo raw_text para decirle \"estas secuencias de texto\n",
        "# de X maxlen preceden al feature o caracter next_char. \n",
        "for i in range(0, len(raw_text) - maxlen, step):\n",
        "    sentences.append(raw_text[i: i + maxlen]) #traemos una sentencia, desde i al maxlen+i\n",
        "    next_chars.append(raw_text[i + maxlen]) #traemos un solo caracter, el maxlen+i\n",
        "print('nb sequences:', len(sentences), 'hay tantos chars:',len(next_chars))\n",
        "print ('ejemplos de sequencias:')\n",
        "print(sentences[:10])\n",
        "print('ejemplos de next chars:')\n",
        "print(next_chars[:10])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 328725 hay tantos chars: 328725\n",
            "ejemplos de sequencias:\n",
            "['\\n\\n\\n\\n\\n                                       ____________\\n                       ', '                                  ____________\\n                               __', '                        ____________\\n                               _______/    ', '              ____________\\n                               _______/            \\\\_', '    ____________\\n                               _______/            \\\\_\\n         ', '______\\n                               _______/            \\\\_\\n                   ', '                            _______/            \\\\_\\n                             ', '                  _______/            \\\\_\\n                             _/      / ', '        _______/            \\\\_\\n                             _/      /           ', '_____/            \\\\_\\n                             _/      /              /\\n     ']\n",
            "ejemplos de next chars:\n",
            "[' ', '_', ' ', '\\n', ' ', ' ', '_', ' ', ' ', ' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuT9hVzA30H3"
      },
      "source": [
        "\n",
        "\n",
        "Building Model\n",
        "\n",
        "In this notebook a small recurrent neural networks is used for both simplicity and \n",
        "because of the training time but if you want to train a more sophisticated model you \n",
        "can increase the size of the network. You can also use a model pretrained on some \n",
        "other text like wikipedia text to both speed up the training process and get \n",
        "better results.\n",
        "\n",
        "\n",
        "\"\"\"we must transform the list of input sequences into the form [samples, time steps, features] expected by an LSTM network.\n",
        "Next we need to rescale the integers to the range 0-to-1 to make the patterns easier to learn by the LSTM network that uses \n",
        "the sigmoid activation function by default.\n",
        "Finally, we need to convert the output patterns (single characters converted to integers) \n",
        "into a one hot encoding. This is so that we can configure the network to predict \n",
        "the probability of each of the 47 different characters in the vocabulary \n",
        "(an easier representation) rather than trying to force it to predict precisely the next \n",
        "character\n",
        "Each y value is converted into a sparse vector with a length of 47, full of zeros except \n",
        "with a 1 in the column for the letter (integer) that the pattern represents.\n",
        "\n",
        "Ej par aun caracter:\n",
        "    [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
        "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
        "  0.  0.  0.  0.  0.  0.  0.  0.]\n",
        "\n",
        "Esto es mas facil para mapear cada entrada como bits en lugar de valores integer\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2HTkjGq31nk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87e49c4-43f9-4610-bbf3-0d0e13b03dce"
      },
      "source": [
        "\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool) #labels?\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool) #features?\n",
        "for i, sentence in enumerate(sentences): #ver esto! creamos matrices\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "print ('ejemplo x ---------------------')\n",
        "print(x[:1])\n",
        "print('size:',x.shape,' y longitud:',x.size)\n",
        "print ('ejemplo y: --------------------')\n",
        "print(y[:1])\n",
        "print('size:',y.shape,' y longitud:',y.size)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ejemplo x ---------------------\n",
            "[[[False False  True ... False False False]\n",
            "  [False False  True ... False False False]\n",
            "  [False False  True ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "size: (328725, 80, 87)  y longitud: 2287926000\n",
            "ejemplo y: --------------------\n",
            "[[False False False False False False False  True False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False]]\n",
            "size: (328725, 87)  y longitud: 28599075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMmQMT_s35P1"
      },
      "source": [
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "#definimos modelos y layers\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "#model.add(Dense(1000, activation='tanh', kernel_initializer='normal', name='idontknow',bias_regularizer='l2', kernel_regularizer='l2'))\n",
        "model.add(Dropout(0.20))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "optimizer = RMSprop(learning_rate=0.1)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fgIRf3HVekV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf2ba56e-f0e7-4e10-b6f9-8d5e17cd0b55"
      },
      "source": [
        "# IMPORTANTE: GUARDAR ESTA CONFIGURACION SI PIENSO USARLA EN OTRO LADO\n",
        "print('guardar la configuracion del modelo somwhere')\n",
        "print(model.summary())\n",
        "print ('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
        "print('input_shape: maxlen:',maxlen,'len(chars):',len(chars))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "guardar la configuracion del modelo somwhere\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_10 (LSTM)               (None, 128)               110592    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 87)                11223     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 87)                0         \n",
            "=================================================================\n",
            "Total params: 121,815\n",
            "Trainable params: 121,815\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
            "input_shape: maxlen: 80 len(chars): 87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sT6S_TJF38hE"
      },
      "source": [
        "\n",
        "# Helper Functions\n",
        "#These helper functions are taken from the official Keras text generation notebook.\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(raw_text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = raw_text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cGDex_g4BxL"
      },
      "source": [
        "# Defining callbacks\n",
        "# aca onda que definimos todos los calls que va a hacer, checkpoints, el modelo\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')\n",
        "\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.001)\n",
        "\n",
        "\n",
        "callbacks = [print_callback, checkpoint, reduce_lr]\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQYo7WtQRhef"
      },
      "source": [
        "**Epochs**\n",
        "    One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE.  \n",
        "**'Batch Size'**\n",
        "    Total number of training examples present in a single batch.  \n",
        "**Iterations** is the number of batches needed to complete one epoch.  \n",
        "*Eg: We can divide the dataset of 2000 examples into batches of 500 then it will take 4 iterations to complete 1 epoch.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M2zuhDN4D6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "17c488f4-4814-467c-910f-67591767aa07"
      },
      "source": [
        "# Training the model ###################################################\n",
        "# ojo puede tardar bocha segun los parametros que le pase\n",
        "model.fit(x, y, batch_size=80, epochs=1, callbacks=callbacks) #con 256 anda bien eh"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 108/4110 [..............................] - ETA: 12:29 - loss: 6.9936"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-68cb9be231de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training the model ###################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ojo puede tardar bocha segun los parametros que le pase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#con 256 anda bien eh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E8QTmqv4vav"
      },
      "source": [
        "#Testing the model\n",
        "\n",
        "# Now that we have a trained network we can test it using a method simular to the on_epoch_end method above.\n",
        "\n",
        "def generate_text(length, diversity):\n",
        "    # Get random starting text\n",
        "    start_index = random.randint(0, len(raw_text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = raw_text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "    return generated\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbBpM2ol5QMk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd95d4f0-0bdc-49cd-936f-85f169b2a8d5"
      },
      "source": [
        "####### generamos asciissss laralalalaa ----------------------------\n",
        "print(generate_text(160, 1.45))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        \\   \\/                  \n",
            "        _______    _____    ____/     _____\\  _\\___       ________\n",
            "        \\     /___/   _/___ \\  (______\\   /_\\/   _/___ ___\\__    /\n",
            "         \\___    /   _/   /--\\___   /\\_    _/   _/   /.\\   _/   / \n",
            "           /__________- _\n",
            "_-______ :__ \n",
            ":_\\____________ :_\n",
            "\n",
            " :/ _____ _____/___\\____ ___#___\\_____\\__# -_____\n",
            "  _#\n",
            "_##--  -#\n",
            "___    \n",
            "   /-/___\n",
            "__- __\n",
            "_ _#/#\n",
            " _ _\n",
            "\n",
            "__  ____ ____\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouWu5hGPZA0L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4j0snFNQaY8"
      },
      "source": [
        "**---- SECCION PARA GUARDAR, BAJAR Y CARGAR MODELOS de KERAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyQrdEQJH2oS"
      },
      "source": [
        "# #### SAVE EL MODELO ####\n",
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/my_ascii_model_1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MK9CvM5TWpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "90c999e8-ecc9-4dad-e43c-5e1de4fb5ecf"
      },
      "source": [
        "#inspeccionamos el modelo salvado y ese directorio\n",
        "# my_model directory\n",
        "!ls saved_model\n",
        "\n",
        "# Contains an assets folder, saved_model.pb, and variables folder.\n",
        "!ls saved_model/my_ascii_model_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_ascii_model_1\n",
            "saved_model/my_ascii_model_1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0De2gx1ZCuw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f9804254-9f5c-4731-fa9c-2ba5ab887b96"
      },
      "source": [
        "# OTRA MANERA DE SALVARLO ##\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6-4zQMbOpwG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "761fbf2f-6e40-4ef3-af43-14788433aaa2"
      },
      "source": [
        "#### DOWNLOAD EL MODELO #### DE GOOGL si lo quiero usar en la maquina local <3\n",
        "from google.colab import files\n",
        "files.download('weights.hdf5') \n",
        "files.download('saved_model/my_ascii_model_1')\n",
        "files.download('model.json')\n",
        "files.download('model.h5')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f7679fd0-5ac3-4be4-afde-4555c79f7b89\", \"weights.hdf5\", 1112240)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_667592ad-0002-4630-b66a-1e77f3b7eead\", \"my_ascii_model_1\", 1112240)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_18392164-89d0-4b09-b3d2-d96e81ec2ed1\", \"model.json\", 1658)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9e09c4e2-3391-45c7-9e59-96576c9be6f5\", \"model.h5\", 558520)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_aqCJjJTfqn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "7464c274-db22-45ac-94d1-1024d3cef020"
      },
      "source": [
        "# ** ##### LOAD ##### a Keras model from the saved model ** ------------------------------\n",
        "model = keras.models.load_model('saved_model/my_ascii_model_1')\n",
        "\n",
        "# Check its architecture\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128)               99840     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 66)                8514      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 66)                0         \n",
            "=================================================================\n",
            "Total params: 108,354\n",
            "Trainable params: 108,354\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8zeeyFKZm2l"
      },
      "source": [
        "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "# load json and create model\n",
        "json_file = open('model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xgnxLW5Tf7"
      },
      "source": [
        "> #### ARLEKA NEXT STEPS: \n",
        "- 1) ver porque en algun momento esta spliteando palabras por espacios o algo asi. asi en el articulo es que genera textos esta basado en adivinar palabras, no next char.  \n",
        "- 2) **con poca diversidad directamente pega partes enteras del file de entrenamiento* :(** \n",
        "  podria usar un mejor tokenizador del ejemplo de: ## Text Generation using Tensorflow, Keras and LSTM\n",
        "Watch Full Video Lesson: https://youtu.be/VAMKuRAh2nc\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1-eOJ_WVEGS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}